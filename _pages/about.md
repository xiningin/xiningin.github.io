---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
<!-- 
{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %} -->

<span class='anchor' id='about-me'></span>

I am currently pursuing a master's degree in the [HCP Laboratory](https://www.sysu-hcp.net/home/) at Sun Yat-sen University in Guangzhou, â€‹â€‹under the supervision of [â€‹â€‹Professor Liang Lin (æ—å€)](https://www.sysu-hcp.net/faculty/lianglin.html)â€‹â€‹.

I graduated from Software Engineering College, [Northeast University](http://www.neu.edu.cn/)(ä¸œåŒ—å¤§å­¦è½¯ä»¶å­¦é™¢) with a bachelor's degree. During my undergraduate studies, I served as a research intern in [Associate Professor Shi Feng (å†¯æ—¶)](https://neu-datamining.github.io/cse/fengshi/)'s [NEU Data Mining group](https://neu-datamining.github.io/), where I conducted research on **Image-Text Multimodal Sentiment Analysis**. Following my undergraduate studies, I joined [DISC Lab](http://www.fudan-disc.com/) led by [Associate Professor Zhongyu Wei (é­å¿ é’°)](http://www.fudan-disc.com/people/zywei) at Fudan University, first through their DISC Beginner project and subsequently as a long-term research intern, focusing on the systematic evaluation and interpretability analysis of **Large Vision-Language Models** (e.g., LLaVA).

I won the National Scholarship (å›½å®¶å¥–å­¦é‡‘), the First Prize Scholarship of the College (é™¢çº§ä¼˜ç§€å­¦ç”Ÿä¸€ç­‰å¥–), the First Prize of the [Yonyou Network Technology Scholarship](https://neunews.neu.edu.cn/info/1005/191311.htm) (ç”¨å‹å¥–å­¦é‡‘ä¸€ç­‰å¥–), etc.

My research interest includes **Video/Image Generation** and **Large Vision Language Model**. 

<!-- # ğŸ”¥ News
- *2022.02*: &nbsp;ğŸ‰ğŸ‰ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;ğŸ‰ğŸ‰ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACL 2025</div><img src='images/VisionRegion.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Activating Distributed Visual Region within LLMs for Efficient and Effective Vision-Language Training and Inference](https://arxiv.org/pdf/2412.12785)

Siyuan Wang, Dianyi Wang, **Chengxing Zhou** (å…±ä¸€), Zejun Li, Zhihao Fan, Xuanjing Huang, Zhongyu Wei
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2025</div><img src='images\convdiff.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Can We Achieve Efficient Diffusion without Self-Attention Distilling Self-Attention into Convolutions](https://arxiv.org/pdf/2412.12785)

ZiYi Dong, **Chengxing Zhou**, Weijian Deng, Pengxu Wei, Xiangyang Ji, Liang Lin
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACMMM 2024</div><img src='images/ReFormEval.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[REFORM-EVAL: Evaluating Large Vision Language Models via Unified Re-Formulation of Task-Oriented Benckmarks](https://dl.acm.org/doi/abs/10.1145/3664647.3681529)

Zejun Li, Ye Wang, Mengfei Du, Qingwen Liu, Binhao Wu, Jiwen Zhang, **Chengxing Zhou** Zhihao Fan, Jie Fu, Jingjing Chen, Zhongyu Wei, Xuanjing Huang
</div>
</div>

<!-- [**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->

# ğŸ– Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# ğŸ“– Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# ğŸ’¬ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# ğŸ’» Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
